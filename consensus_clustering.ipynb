{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import ttest_ind, chisquare\n",
    "\n",
    "import scipy.cluster as cluster\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_et = pd.read_csv('pheno_et.csv')\n",
    "pheno_et.set_index(['EID'], inplace=True)\n",
    "pheno_et = pheno_et.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('et_time_series_x.npy')\n",
    "y = np.load('et_time_series_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.clip(x, 0, 800)\n",
    "y = np.clip(y, 0, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = np.stack((x, y), axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = np.zeros((et.shape[0], et.shape[0]))\n",
    "\n",
    "min_e = np.inf\n",
    "for i in range(et.shape[0] - 1):\n",
    "    for j in range(i + 1, et.shape[0]):\n",
    "        e = np.mean(np.sqrt((et[i,:,0] - et[j,:,0])**2 + (et[i,:,1] - et[j,:,1])**2))\n",
    "        if e < min_e:\n",
    "            min_e = e\n",
    "        dis[i,j] = e\n",
    "        dis[j,i] = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrapping\n",
    "niter = 1000\n",
    "chunk = int(et.shape[0] * 0.9)\n",
    "\n",
    "# create indicator matrix of selected sample pairs\n",
    "ind_mat = np.zeros((et.shape[0], et.shape[0]))\n",
    "\n",
    "# create consensus matrices for K = 2:20\n",
    "consensus_mats = [np.zeros((et.shape[0], et.shape[0])) for i in range(19)]\n",
    "\n",
    "for i in range(niter):\n",
    "    idx = np.random.choice(et.shape[0], chunk, replace=False) # 90% resampling\n",
    "    idx.sort()\n",
    "    \n",
    "    # update indicator matrix\n",
    "    idx_a = np.zeros((et.shape[0],))\n",
    "    idx_a[idx] = 1\n",
    "    idx_a = idx_a[:,np.newaxis]\n",
    "    ac = np.dot(idx_a, idx_a.T)\n",
    "    ac[ac != 1] = 0\n",
    "    ind_mat += ac\n",
    "    \n",
    "    # partition distance matrix and perform hierarchical clustering for K = 2:20\n",
    "    dis_boot = dis[idx][:,idx]\n",
    "    cd = distance.squareform(dis_boot) # since inputting dense distance matrix into linkage function, must convert to 1D condensed distance vector\n",
    "    Z = cluster.hierarchy.linkage(cd, method='ward')\n",
    "    for c in range(2, 21):\n",
    "        cm = consensus_mats[c - 2]\n",
    "        clusters = cluster.hierarchy.fcluster(Z, c, criterion='maxclust') # 'maxclust' cuts dendrogram so that it creates c optimal clusters\n",
    "        \n",
    "        # in order to use the clever method below, preserve unselected indices as 0 (cluster labels start at 1)\n",
    "        ct = np.zeros((et.shape[0]),)\n",
    "        ct[idx] = clusters\n",
    "        \n",
    "        ####### extremely clever way of creating consensus matrix -- taken from Aki's PyBASC #######\n",
    "        ct = ct[:,np.newaxis]\n",
    "        cm += (np.dot(ct**-1., ct.T) == 1).astype(np.float64)\n",
    "        ############################################################################################\n",
    "        \n",
    "for mat in consensus_mats:\n",
    "    mat /= ind_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CDF(X, resolution=100):\n",
    "    \"\"\"\n",
    "    Calculate empirical cumulative distribution (CDF) for given consensus matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    \n",
    "    X = np.copy(X)\n",
    "    ur,uc = np.triu_indices(X.shape[0],1)\n",
    "    X = X[ur,uc]\n",
    "    \n",
    "    cdf = []\n",
    "    for i in np.linspace(0,1,resolution):\n",
    "        cdf.append(np.sum(X <= i) / (N * (N - 1) / 2))\n",
    "        \n",
    "    return np.array(cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdfs = []\n",
    "for mat in consensus_mats:\n",
    "    cdfs.append(CDF(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for cdf in cdfs:\n",
    "    plt.plot(cdf)\n",
    "plt.xticks(ticks=np.linspace(0,100,6), labels=[0,0.2,0.4,0.6,0.8,1])\n",
    "plt.title('Empirical CDFs for K = 2:20', fontsize=18)\n",
    "plt.xlabel('Consensus index value', fontsize=18)\n",
    "plt.ylabel('CDF', fontsize=18)\n",
    "plt.savefig('figs_clust/eucl_cdf.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = np.mean(np.diff(np.linspace(0,1,100)))\n",
    "auc = []\n",
    "for cdf in cdfs:\n",
    "    auc.append(np.trapz(cdf, dx=dx))\n",
    "auc = [auc[0]] + auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_auc = np.diff(np.array(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(del_auc, 'bo-')\n",
    "_ = plt.xticks(ticks=np.arange(19), labels=np.arange(2,21))\n",
    "plt.title('Change in AUC in CDFs', fontsize=18)\n",
    "plt.xlabel('Number of clusters', fontsize=18)\n",
    "plt.ylabel('Change in AUC', fontsize=18)\n",
    "plt.savefig('figs_clust/eucl_del_cdf.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = np.argmax(del_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.copy(consensus_mats[best])\n",
    "cm = 1 - cm\n",
    "cd = distance.squareform(cm)\n",
    "Z = cluster.hierarchy.linkage(cd, method='ward')\n",
    "clusters = cluster.hierarchy.fcluster(Z, best + 2, criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(clusters, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peuc = pheno_et.copy()\n",
    "# peuc['clusters'] = clusters\n",
    "# peuc.to_csv('et_subs_euc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "dn = cluster.hierarchy.dendrogram(Z, color_threshold=5.2, no_labels=True)\n",
    "plt.title('Dendrogram of optimal consensus matrix (K=%d)' % (best + 2), fontsize=18)\n",
    "plt.savefig('figs_clust/eucl_dendrogram.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.copy(consensus_mats[best])\n",
    "cm = cm[np.argsort(clusters)][:,np.argsort(clusters)]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "im = plt.imshow(cm, cmap='Reds')\n",
    "plt.colorbar(im)\n",
    "plt.title('Consensus matrix (K=%d)' % (best + 2), fontsize=18)\n",
    "plt.savefig('figs_clust/eucl_consensus.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, c = np.unique(clusters, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(35,20))\n",
    "\n",
    "for i in range(u.size):\n",
    "    ax[0].plot(np.mean(x[clusters == u[i]], axis=0))\n",
    "    ax[1].plot(np.mean(y[clusters == u[i]], axis=0), label='%d; N=%d' % (u[i], c[i]))\n",
    "ax[0].set_title('x-direction mean time series', fontsize=18, fontweight='bold')\n",
    "ax[1].set_title('y-direction mean time series', fontsize=18, fontweight='bold')\n",
    "ax[1].legend(loc=0, fontsize=18)\n",
    "fig.savefig('figs_clust/eucl_mts.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peuc = pheno_et.copy()\n",
    "peuc['clusters'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ols('Age ~ C(clusters)', data=peuc).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = []\n",
    "for i in u:\n",
    "    freq.append(\n",
    "        np.sum(peuc['Sex'][peuc['clusters'] == i] == 0) / np.sum(peuc['clusters'] == i)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisquare(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 1, figsize=(30,30))\n",
    "sns.violinplot(x='clusters', y='ASSQ_Total', data=peuc, ax=ax[0])\n",
    "sns.violinplot(x='clusters', y='SCQ_Total', data=peuc, ax=ax[1])\n",
    "sns.violinplot(x='clusters', y='SAS_Tot', data=peuc, ax=ax[2])\n",
    "sns.violinplot(x='clusters', y='SRS_Total_T', data=peuc, ax=ax[3])\n",
    "ax[0].set_title('ASSQ_Total', fontsize=18, fontweight='bold')\n",
    "ax[1].set_title('SCQ_Total', fontsize=18, fontweight='bold')\n",
    "ax[2].set_title('SAS_Tot', fontsize=18, fontweight='bold')\n",
    "ax[3].set_title('SRS_Total_T', fontsize=18, fontweight='bold')\n",
    "fig.savefig('figs_clust/eucl_violin.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_c = []\n",
    "for i in np.unique(clusters):\n",
    "    pheno_c.append(pheno_et.iloc[clusters == i,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = np.zeros((np.unique(clusters).size, np.unique(clusters).size, 4))\n",
    "for i in range(np.unique(clusters).size - 1):\n",
    "    for j in range(i + 1, np.unique(clusters).size):\n",
    "        for k in range(4):\n",
    "            p = ttest_ind(pheno_c[i].iloc[:,k], pheno_c[j].iloc[:,k], equal_var=False)[1]\n",
    "            pvals[i,j,k] = p\n",
    "            pvals[j,i,k] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_corr = np.zeros(pvals.shape)\n",
    "nmu = np.triu_indices(pvals.shape[0], 1)\n",
    "for i in range(pvals.shape[2]):\n",
    "    nm = np.triu_indices(np.unique(clusters).size, 1)\n",
    "    p_unc = pvals[...,i][nm[0],nm[1]]\n",
    "    res = multipletests(p_unc, method='fdr_bh')\n",
    "    p_corr[nmu[0],nmu[1],i] = res[1]\n",
    "    p_corr[...,i] += p_corr[...,i].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(11,11))\n",
    "ax_flat = ax.flat\n",
    "scores = pheno_et.columns.tolist()[:-1]\n",
    "for i in range(p_corr.shape[2]):\n",
    "    im = ax_flat[i].imshow(p_corr[...,i], cmap='jet', vmax=0.05)\n",
    "    ax_flat[i].set_title(scores[i], fontsize=18)\n",
    "    ax_flat[i].set_xticks(np.arange(p_corr.shape[0]))\n",
    "    ax_flat[i].set_yticks(np.arange(p_corr.shape[0]))\n",
    "    ax_flat[i].set_xticklabels(np.arange(p_corr.shape[0]) + 1)\n",
    "    ax_flat[i].set_yticklabels(np.arange(p_corr.shape[0]) + 1)\n",
    "cbar = fig.colorbar(im, ax=ax.ravel().tolist(), shrink=0.95)\n",
    "fig.savefig('figs_clust/eucl_pheno.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_cos = np.zeros((et.shape[0], et.shape[0]))\n",
    "\n",
    "# originally, origin of ET data is top left corner--this does not suit cosine distance well, so need to center data at center of screen\n",
    "et[...,0] -= 400\n",
    "et[...,1] -= 300\n",
    "\n",
    "min_cos = np.inf\n",
    "for i in range(et.shape[0] - 1):\n",
    "    for j in range(i + 1, et.shape[0]):\n",
    "        cos = distance.cosine(np.concatenate((et[i,:,0], et[i,:,1])), np.concatenate((et[j,:,0], et[j,:,1])))\n",
    "        if cos < min_cos:\n",
    "            min_cos = cos\n",
    "        dis_cos[i,j] = cos\n",
    "        dis_cos[j,i] = cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrapping\n",
    "niter = 1000\n",
    "chunk = int(et.shape[0] * 0.9)\n",
    "\n",
    "# create indicator matrix of selected sample pairs\n",
    "ind_mat = np.zeros((et.shape[0], et.shape[0]))\n",
    "\n",
    "# create consensus matrices for K = 2:20\n",
    "consensus_mats_cos = [np.zeros((et.shape[0], et.shape[0])) for i in range(19)]\n",
    "\n",
    "for i in range(niter):\n",
    "    idx = np.random.choice(et.shape[0], chunk, replace=False) # 90% resampling\n",
    "    idx.sort()\n",
    "    \n",
    "    # update indicator matrix\n",
    "    idx_a = np.zeros((et.shape[0],))\n",
    "    idx_a[idx] = 1\n",
    "    idx_a = idx_a[:,np.newaxis]\n",
    "    ac = np.dot(idx_a, idx_a.T)\n",
    "    ac[ac != 1] = 0\n",
    "    ind_mat += ac\n",
    "    \n",
    "    # partition distance matrix and perform hierarchical clustering for K = 2:20\n",
    "    dis_boot = dis_cos[idx][:,idx]\n",
    "    cd = distance.squareform(dis_boot) # since inputting dense distance matrix into linkage function, must convert to 1D condensed distance vector\n",
    "    Z = cluster.hierarchy.linkage(cd, method='ward')\n",
    "    for c in range(2, 21):\n",
    "        cm = consensus_mats_cos[c - 2]\n",
    "        clusters = cluster.hierarchy.fcluster(Z, c, criterion='maxclust') # 'maxclust' cuts dendrogram so that it creates c optimal clusters\n",
    "        \n",
    "        # in order to use the clever method below, preserve unselected indices as 0 (cluster labels start at 1)\n",
    "        ct = np.zeros((et.shape[0]),)\n",
    "        ct[idx] = clusters\n",
    "        \n",
    "        ####### extremely clever way of creating consensus matrix -- taken from Aki's PyBASC #######\n",
    "        ct = ct[:,np.newaxis]\n",
    "        cm += (np.dot(ct**-1., ct.T) == 1).astype(np.float64)\n",
    "        ############################################################################################\n",
    "        \n",
    "for mat in consensus_mats_cos:\n",
    "    mat /= ind_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdfs = []\n",
    "for mat in consensus_mats_cos:\n",
    "    cdfs.append(CDF(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for cdf in cdfs:\n",
    "    plt.plot(cdf)\n",
    "plt.xticks(ticks=np.linspace(0,100,6), labels=[0,0.2,0.4,0.6,0.8,1])\n",
    "plt.title('Empirical CDFs for K = 2:20', fontsize=18)\n",
    "plt.xlabel('Consensus index value', fontsize=18)\n",
    "plt.ylabel('CDF', fontsize=18)\n",
    "plt.savefig('figs_clust/cos_cdf.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = np.mean(np.diff(np.linspace(0,1,100)))\n",
    "auc = []\n",
    "for cdf in cdfs:\n",
    "    auc.append(np.trapz(cdf, dx=dx))\n",
    "auc = [auc[0]] + auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_auc = np.diff(np.array(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(del_auc, 'bo-')\n",
    "_ = plt.xticks(ticks=np.arange(19), labels=np.arange(2,21))\n",
    "plt.title('Change in AUC in CDFs', fontsize=18)\n",
    "plt.xlabel('Number of clusters', fontsize=18)\n",
    "plt.ylabel('Change in AUC', fontsize=18)\n",
    "plt.savefig('figs_clust/cos_del_cdf.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = np.argmax(del_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.copy(consensus_mats_cos[best])\n",
    "cm = 1 - cm\n",
    "cd = distance.squareform(cm)\n",
    "Z = cluster.hierarchy.linkage(cd, method='ward')\n",
    "clusters = cluster.hierarchy.fcluster(Z, best + 2, criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(clusters, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcos = pheno_et.copy()\n",
    "# pcos['clusters'] = clusters\n",
    "# pcos.to_csv('et_subs_cos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "dn = cluster.hierarchy.dendrogram(Z, no_labels=True)\n",
    "plt.title('Dendrogram of optimal consensus matrix (K=%d)' % (best + 2), fontsize=18)\n",
    "plt.savefig('figs_clust/cos_dendrogram.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.copy(consensus_mats_cos[best])\n",
    "cm = cm[np.argsort(clusters)][:,np.argsort(clusters)]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "im = plt.imshow(cm, cmap='Reds')\n",
    "plt.colorbar(im)\n",
    "plt.title('Consensus matrix (K=%d)' % (best + 2), fontsize=18)\n",
    "plt.savefig('figs_clust/cos_consensus.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, c = np.unique(clusters, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(35,20))\n",
    "\n",
    "for i in range(u.size):\n",
    "    ax[0].plot(np.mean(x[clusters == u[i]], axis=0))\n",
    "    ax[1].plot(np.mean(y[clusters == u[i]], axis=0), label='%d; N=%d' % (u[i], c[i]))\n",
    "ax[0].set_title('x-direction mean time series', fontsize=18, fontweight='bold')\n",
    "ax[1].set_title('y-direction mean time series', fontsize=18, fontweight='bold')\n",
    "ax[1].legend(loc=0, fontsize=18)\n",
    "fig.savefig('figs_clust/cos_mts.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcos = pheno_et.copy()\n",
    "pcos['clusters'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ols('Age ~ C(clusters)', data=pcos).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = []\n",
    "for i in u:\n",
    "    freq.append(\n",
    "        np.sum(pcos['Sex'][pcos['clusters'] == i] == 0) / np.sum(pcos['clusters'] == i)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisquare(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 1, figsize=(30,30))\n",
    "sns.violinplot(x='clusters', y='ASSQ_Total', data=pcos, ax=ax[0])\n",
    "sns.violinplot(x='clusters', y='SCQ_Total', data=pcos, ax=ax[1])\n",
    "sns.violinplot(x='clusters', y='SAS_Tot', data=pcos, ax=ax[2])\n",
    "sns.violinplot(x='clusters', y='SRS_Total_T', data=pcos, ax=ax[3])\n",
    "ax[0].set_title('ASSQ_Total', fontsize=18, fontweight='bold')\n",
    "ax[1].set_title('SCQ_Total', fontsize=18, fontweight='bold')\n",
    "ax[2].set_title('SAS_Tot', fontsize=18, fontweight='bold')\n",
    "ax[3].set_title('SRS_Total_T', fontsize=18, fontweight='bold')\n",
    "fig.savefig('figs_clust/cos_violin.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_c = []\n",
    "for i in np.unique(clusters):\n",
    "    pheno_c.append(pheno_et.iloc[clusters == i,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = np.zeros((np.unique(clusters).size, np.unique(clusters).size, 4))\n",
    "for i in range(np.unique(clusters).size - 1):\n",
    "    for j in range(i + 1, np.unique(clusters).size):\n",
    "        for k in range(4):\n",
    "            p = ttest_ind(pheno_c[i].iloc[:,k], pheno_c[j].iloc[:,k], equal_var=False)[1]\n",
    "            pvals[i,j,k] = p\n",
    "            pvals[j,i,k] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_corr = np.zeros(pvals.shape)\n",
    "nmu = np.triu_indices(pvals.shape[0], 1)\n",
    "for i in range(pvals.shape[2]):\n",
    "    nm = np.triu_indices(np.unique(clusters).size, 1)\n",
    "    p_unc = pvals[...,i][nm[0],nm[1]]\n",
    "    res = multipletests(p_unc, method='fdr_bh')\n",
    "    p_corr[nmu[0],nmu[1],i] = res[1]\n",
    "    p_corr[...,i] += p_corr[...,i].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(11,11))\n",
    "ax_flat = ax.flat\n",
    "scores = pheno_et.columns.tolist()[:-1]\n",
    "for i in range(p_corr.shape[2]):\n",
    "    im = ax_flat[i].imshow(p_corr[...,i], cmap='jet', vmax=0.05)\n",
    "    ax_flat[i].set_title(scores[i], fontsize=18)\n",
    "    ax_flat[i].set_xticks(np.arange(p_corr.shape[0]))\n",
    "    ax_flat[i].set_yticks(np.arange(p_corr.shape[0]))\n",
    "    ax_flat[i].set_xticklabels(np.arange(p_corr.shape[0]) + 1)\n",
    "    ax_flat[i].set_yticklabels(np.arange(p_corr.shape[0]) + 1)\n",
    "cbar = fig.colorbar(im, ax=ax.ravel().tolist(), shrink=0.95)\n",
    "fig.savefig('figs_clust/cos_pheno.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination of Euclidean and cosine distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance on z-scored time series\n",
    "xz = np.copy(x)\n",
    "yz = np.copy(y)\n",
    "xz = (xz - np.mean(xz, axis=1, keepdims=True)) / np.std(xz, axis=1, dtype=np.float64, ddof=1, keepdims=True)\n",
    "yz = (yz - np.mean(yz, axis=1, keepdims=True)) / np.std(yz, axis=1, dtype=np.float64, ddof=1, keepdims=True)\n",
    "et_euc = np.stack((xz, yz), axis=2)\n",
    "\n",
    "eucz = np.zeros((et_euc.shape[0], et_euc.shape[0]))\n",
    "for i in range(et_euc.shape[0] - 1):\n",
    "    for j in range(i + 1, et_euc.shape[0]):\n",
    "        e = np.mean(np.sqrt((et_euc[i,:,0] - et_euc[j,:,0])**2 + (et_euc[i,:,1] - et_euc[j,:,1])**2))\n",
    "        eucz[i,j] = e\n",
    "        eucz[j,i] = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine distance on z-scored time series\n",
    "xz = np.copy(x)\n",
    "yz = np.copy(y)\n",
    "xz -= 400\n",
    "yz -= 300\n",
    "xz = (xz - np.mean(xz, axis=1, keepdims=True)) / np.std(xz, axis=1, dtype=np.float64, ddof=1, keepdims=True)\n",
    "yz = (yz - np.mean(yz, axis=1, keepdims=True)) / np.std(yz, axis=1, dtype=np.float64, ddof=1, keepdims=True)\n",
    "et_cos = np.stack((xz, yz), axis=2)\n",
    "\n",
    "cosz = np.zeros((et_cos.shape[0], et_cos.shape[0]))\n",
    "for i in range(et_cos.shape[0] - 1):\n",
    "    for j in range(i + 1, et_cos.shape[0]):\n",
    "        cos = distance.cosine(np.concatenate((et_cos[i,:,0], et_cos[i,:,1])), np.concatenate((et_cos[j,:,0], et_cos[j,:,1])))\n",
    "        cosz[i,j] = cos\n",
    "        cosz[j,i] = cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_both = (eucz + cosz) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrapping\n",
    "niter = 1000\n",
    "chunk = int(et.shape[0] * 0.9)\n",
    "\n",
    "# create indicator matrix of selected sample pairs\n",
    "ind_mat = np.zeros((et.shape[0], et.shape[0]))\n",
    "\n",
    "# create consensus matrices for K = 2:20\n",
    "consensus_mats_both = [np.zeros((et.shape[0], et.shape[0])) for i in range(19)]\n",
    "\n",
    "for i in range(niter):\n",
    "    idx = np.random.choice(et.shape[0], chunk, replace=False) # 90% resampling\n",
    "    idx.sort()\n",
    "    \n",
    "    # update indicator matrix\n",
    "    idx_a = np.zeros((et.shape[0],))\n",
    "    idx_a[idx] = 1\n",
    "    idx_a = idx_a[:,np.newaxis]\n",
    "    ac = np.dot(idx_a, idx_a.T)\n",
    "    ac[ac != 1] = 0\n",
    "    ind_mat += ac\n",
    "    \n",
    "    # partition distance matrix and perform hierarchical clustering for K = 2:20\n",
    "    dis_boot = dis_both[idx][:,idx]\n",
    "    cd = distance.squareform(dis_boot) # since inputting dense distance matrix into linkage function, must convert to 1D condensed distance vector\n",
    "    Z = cluster.hierarchy.linkage(cd, method='ward')\n",
    "    for c in range(2, 21):\n",
    "        cm = consensus_mats_both[c - 2]\n",
    "        clusters = cluster.hierarchy.fcluster(Z, c, criterion='maxclust') # 'maxclust' cuts dendrogram so that it creates c optimal clusters\n",
    "        \n",
    "        # in order to use the clever method below, preserve unselected indices as 0 (cluster labels start at 1)\n",
    "        ct = np.zeros((et.shape[0]),)\n",
    "        ct[idx] = clusters\n",
    "        \n",
    "        ####### extremely clever way of creating consensus matrix -- taken from Aki's PyBASC #######\n",
    "        ct = ct[:,np.newaxis]\n",
    "        cm += (np.dot(ct**-1., ct.T) == 1).astype(np.float64)\n",
    "        ############################################################################################\n",
    "        \n",
    "for mat in consensus_mats_both:\n",
    "    mat /= ind_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdfs = []\n",
    "for mat in consensus_mats_both:\n",
    "    cdfs.append(CDF(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for cdf in cdfs:\n",
    "    plt.plot(cdf)\n",
    "plt.xticks(ticks=np.linspace(0,100,6), labels=[0,0.2,0.4,0.6,0.8,1])\n",
    "plt.title('Empirical CDFs for K = 2:20', fontsize=18)\n",
    "plt.xlabel('Consensus index value', fontsize=18)\n",
    "plt.ylabel('CDF', fontsize=18)\n",
    "plt.savefig('figs_clust/both_cdf.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = np.mean(np.diff(np.linspace(0,1,100)))\n",
    "auc = []\n",
    "for cdf in cdfs:\n",
    "    auc.append(np.trapz(cdf, dx=dx))\n",
    "auc = [auc[0]] + auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_auc = np.diff(np.array(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(del_auc, 'bo-')\n",
    "_ = plt.xticks(ticks=np.arange(19), labels=np.arange(2,21))\n",
    "plt.title('Change in AUC in CDFs', fontsize=18)\n",
    "plt.xlabel('Number of clusters', fontsize=18)\n",
    "plt.ylabel('Change in AUC', fontsize=18)\n",
    "plt.savefig('figs_clust/both_del_cdf.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = np.argmax(del_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.copy(consensus_mats_both[best])\n",
    "cm = 1 - cm\n",
    "cd = distance.squareform(cm)\n",
    "Z = cluster.hierarchy.linkage(cd, method='ward')\n",
    "clusters = cluster.hierarchy.fcluster(Z, best + 2, criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(clusters, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pboth = pheno_et.copy()\n",
    "# pboth['clusters'] = clusters\n",
    "# pboth.to_csv('et_subs_both.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "dn = cluster.hierarchy.dendrogram(Z, color_threshold=4.5, no_labels=True)\n",
    "plt.title('Dendrogram of optimal consensus matrix (K=%d)' % (best + 2), fontsize=18)\n",
    "plt.savefig('figs_clust/both_dendrogram.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.copy(consensus_mats_both[best])\n",
    "cm = cm[np.argsort(clusters)][:,np.argsort(clusters)]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "im = plt.imshow(cm, cmap='Reds')\n",
    "plt.colorbar(im)\n",
    "plt.title('Consensus matrix (K=%d)' % (best + 2), fontsize=18)\n",
    "plt.savefig('figs_clust/both_consensus.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, c = np.unique(clusters, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(35,20))\n",
    "\n",
    "for i in range(u.size):\n",
    "    ax[0].plot(np.mean(x[clusters == u[i]], axis=0))\n",
    "    ax[1].plot(np.mean(y[clusters == u[i]], axis=0), label='%d; N=%d' % (u[i], c[i]))\n",
    "ax[0].set_title('x-direction mean time series', fontsize=18, fontweight='bold')\n",
    "ax[1].set_title('y-direction mean time series', fontsize=18, fontweight='bold')\n",
    "ax[1].legend(loc=0, fontsize=18)\n",
    "fig.savefig('figs_clust/both_mts.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pboth = pheno_et.copy()\n",
    "pboth['clusters'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ols('Age ~ C(clusters)', data=pboth).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = []\n",
    "for i in u:\n",
    "    freq.append(\n",
    "        np.sum(pboth['Sex'][pboth['clusters'] == i] == 0) / np.sum(pboth['clusters'] == i)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chisquare(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 1, figsize=(30,30))\n",
    "sns.violinplot(x='clusters', y='ASSQ_Total', data=pboth, ax=ax[0])\n",
    "sns.violinplot(x='clusters', y='SCQ_Total', data=pboth, ax=ax[1])\n",
    "sns.violinplot(x='clusters', y='SAS_Tot', data=pboth, ax=ax[2])\n",
    "sns.violinplot(x='clusters', y='SRS_Total_T', data=pboth, ax=ax[3])\n",
    "ax[0].set_title('ASSQ_Total', fontsize=18, fontweight='bold')\n",
    "ax[1].set_title('SCQ_Total', fontsize=18, fontweight='bold')\n",
    "ax[2].set_title('SAS_Tot', fontsize=18, fontweight='bold')\n",
    "ax[3].set_title('SRS_Total_T', fontsize=18, fontweight='bold')\n",
    "fig.savefig('figs_clust/both_violin.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_c = []\n",
    "for i in np.unique(clusters):\n",
    "    pheno_c.append(pheno_et.iloc[clusters == i,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvals = np.zeros((np.unique(clusters).size, np.unique(clusters).size, 4))\n",
    "for i in range(np.unique(clusters).size - 1):\n",
    "    for j in range(i + 1, np.unique(clusters).size):\n",
    "        for k in range(4):\n",
    "            p = ttest_ind(pheno_c[i].iloc[:,k], pheno_c[j].iloc[:,k], equal_var=False)[1]\n",
    "            pvals[i,j,k] = p\n",
    "            pvals[j,i,k] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_corr = np.zeros(pvals.shape)\n",
    "nmu = np.triu_indices(pvals.shape[0], 1)\n",
    "for i in range(pvals.shape[2]):\n",
    "    nm = np.triu_indices(np.unique(clusters).size, 1)\n",
    "    p_unc = pvals[...,i][nm[0],nm[1]]\n",
    "    res = multipletests(p_unc, method='fdr_bh')\n",
    "    p_corr[nmu[0],nmu[1],i] = res[1]\n",
    "    p_corr[...,i] += p_corr[...,i].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(11,11))\n",
    "ax_flat = ax.flat\n",
    "scores = pheno_et.columns.tolist()[:-1]\n",
    "for i in range(p_corr.shape[2]):\n",
    "    im = ax_flat[i].imshow(p_corr[...,i], cmap='jet', vmax=0.05)\n",
    "    ax_flat[i].set_title(scores[i], fontsize=18)\n",
    "    ax_flat[i].set_xticks(np.arange(p_corr.shape[0]))\n",
    "    ax_flat[i].set_yticks(np.arange(p_corr.shape[0]))\n",
    "    ax_flat[i].set_xticklabels(np.arange(p_corr.shape[0]) + 1)\n",
    "    ax_flat[i].set_yticklabels(np.arange(p_corr.shape[0]) + 1)\n",
    "cbar = fig.colorbar(im, ax=ax.ravel().tolist(), shrink=0.95)\n",
    "fig.savefig('figs_clust/both_pheno.png', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
